{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "\n",
    "from evolution.evaluation.evaluator import EnROADSEvaluator\n",
    "from evolution.utils import process_config\n",
    "from experiments.experiment_utils import NNExperimenter, DirectExperimenter\n",
    "from enroadspy import load_input_specs\n",
    "from enroadspy.generate_url import open_browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = Path(\"results/app1\")\n",
    "results_df = pd.read_csv(results_dir / \"results.csv\")\n",
    "n_generations = results_df[\"gen\"].max()\n",
    "with open(results_dir / \"config.yml\", \"r\", encoding=\"utf-8\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "config = process_config(config)\n",
    "\n",
    "print(config)\n",
    "\n",
    "context = config[\"context\"]\n",
    "actions = config[\"actions\"]\n",
    "outcomes = config[\"outcomes\"]\n",
    "outcome_keys = list(outcomes.keys())\n",
    "n_elites = config[\"evolution_params\"][\"n_elites\"]\n",
    "print(n_generations, outcomes, len(actions), len(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_specs = load_input_specs()\n",
    "\n",
    "evaluator = EnROADSEvaluator(context, actions, outcomes, n_jobs=1, batch_size=config[\"batch_size\"], device=config[\"device\"])\n",
    "if len(context) > 0:\n",
    "    experimenter = NNExperimenter(results_dir)\n",
    "else:\n",
    "    experimenter = DirectExperimenter(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_space_size(actions: list[str]):\n",
    "    input_specs = load_input_specs()\n",
    "    size = 1\n",
    "    for action in actions:\n",
    "        row = input_specs[input_specs[\"id\"] == action].iloc[0]\n",
    "        if row[\"kind\"] == \"switch\":\n",
    "            size *= 2\n",
    "        elif row[\"kind\"] == \"slider\":\n",
    "            combs = int((row[\"maxValue\"] - row[\"minValue\"]) / row[\"step\"])\n",
    "            size *= combs\n",
    "    \n",
    "    size = int(size)\n",
    "    return size\n",
    "\n",
    "size = get_search_space_size(actions)\n",
    "n_atoms = 1e82\n",
    "print(f\"{size:.2e}\")\n",
    "f\"{size / n_atoms:.2e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_actions = {}\n",
    "baseline_df = evaluator.enroads_runner.evaluate_actions(baseline_actions)\n",
    "baseline_metrics = evaluator.outcome_manager.process_outcomes(baseline_actions, baseline_df)\n",
    "for outcome in outcomes:\n",
    "    print(f\"{outcome}: {baseline_metrics[outcome]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pareto = results_df[(results_df[\"gen\"] == n_generations) & (results_df[\"rank\"] == 1)]\n",
    "final_pareto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_input, context_vals = evaluator.context_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evenly_sample(lst, m):\n",
    "    middle = lst[1:-1]\n",
    "    step = len(middle) / (m-2)\n",
    "    sample = [middle[int(i * step)] for i in range(m-2)]\n",
    "    sample = [lst[0]] + sample + [lst[-1]]\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(final_pareto) < 10:\n",
    "    sample_points = final_pareto[\"cand_id\"].tolist()\n",
    "else:\n",
    "    outcome_sort = outcome_keys[1]\n",
    "    sample_points = final_pareto.sort_values(outcome_sort, ascending=outcomes[outcome_sort])[\"cand_id\"].tolist()\n",
    "    sample_points = evenly_sample(sample_points, 9)\n",
    "\n",
    "    # sample_pareto = final_pareto[final_pareto[\"Temperature change from 1850\"] <= 1.5].sort_values(\"Cost change year\", ascending=False)\n",
    "    # sample_points = evenly_sample(sample_pareto[\"cand_id\"].tolist(), 9)\n",
    "    # sample_pareto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_objective_over_time(outcome: str, results_df: pd.DataFrame, n_generations: int):\n",
    "    best = []\n",
    "    worst = []\n",
    "    avg = []\n",
    "    elite = []\n",
    "    x = range(1, n_generations + 1)\n",
    "    for gen in x:\n",
    "        gen_df = results_df[results_df[\"gen\"] == gen]\n",
    "        pareto = gen_df[gen_df[\"rank\"] == 1]\n",
    "        scores = pareto.sort_values(\"distance\", ascending=False)[outcome]\n",
    "        best.append(scores.max())\n",
    "        worst.append(scores.min())\n",
    "        avg.append(scores.mean())\n",
    "        elite.append(scores.iloc[:n_elites].mean())\n",
    "    \n",
    "    # plt.plot(range(gens), [baseline_df[outcome].iloc[-1] for _ in range(gens)], label=f\"Baseline {outcome}\", color=\"black\")\n",
    "    \n",
    "    plt.plot(x, best, label=f\"Highest {outcome}\")\n",
    "    plt.plot(x, elite, label=f\"Elite {outcome}\")\n",
    "    plt.plot(x, avg, label=f\"Avg {outcome}\")\n",
    "    plt.plot(x, worst, label=f\"Lowest {outcome}\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(outcome)\n",
    "    plt.title(f\"{outcome} over time\")\n",
    "    plt.show()\n",
    "\n",
    "for outcome in outcomes:\n",
    "    plot_objective_over_time(outcome, results_df, n_generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_two_objective(outcome1: str, outcome2: str, results_df: pd.DataFrame, gens: list[int], pareto=True):\n",
    "\n",
    "    gen_dfs = []\n",
    "    for gen in gens:\n",
    "        gen_df = results_df[results_df[\"gen\"] == gen]\n",
    "        gen_df = gen_df[gen_df[\"rank\"] == 1] if pareto else gen_df\n",
    "        gen_df[\"color\"] = gen\n",
    "        gen_dfs.append(gen_df)\n",
    "    \n",
    "    total_gen_df = pd.concat(gen_dfs)\n",
    "    cmap = \"viridis_r\" if len(gens) != 1 else \"viridis\"\n",
    "    fig, ax = plt.subplots()\n",
    "    scatter = ax.scatter(total_gen_df[outcome1], total_gen_df[outcome2], c=total_gen_df[\"color\"], cmap=cmap)\n",
    "\n",
    "    title = f\"{outcome1} vs {outcome2} Final Pareto\"\n",
    "\n",
    "    if len(gens) != 1:\n",
    "        cbar = fig.colorbar(scatter)\n",
    "        cbar.set_label(\"Generation\", rotation=270, labelpad=15)\n",
    "        title = f\"{outcome1} vs {outcome2} over Evolution\"\n",
    "    \n",
    "    ax.set_title(title)\n",
    "\n",
    "    ax.set_ylabel(outcome2)\n",
    "    ax.set_xlabel(outcome1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_objective(outcome_keys[1], outcome_keys[0], results_df, [n_generations])\n",
    "x = range(1, n_generations + 1, 20)\n",
    "plot_two_objective(outcome_keys[0], outcome_keys[1], results_df, x)\n",
    "plot_two_objective(outcome_keys[1], outcome_keys[2], results_df, x)\n",
    "plot_two_objective(outcome_keys[0], outcome_keys[2], results_df, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cand_ids = []\n",
    "for outcome, ascending in outcomes.items():\n",
    "    best_cand_ids.append(final_pareto.sort_values(outcome, ascending=ascending).iloc[0][\"cand_id\"])\n",
    "    print(final_pareto.sort_values(outcome, ascending=ascending).iloc[0][outcome_keys])\n",
    "    print()\n",
    "best_cand_ids = list(set(best_cand_ids))\n",
    "best_cand_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_parallel_coordinates(cand_ids: list[str], results_df: pd.DataFrame):\n",
    "    coords_dicts = []\n",
    "    for cand_id in cand_ids:\n",
    "        gen = int(cand_id.split(\"_\")[0])\n",
    "        gen_df = results_df[results_df[\"gen\"] == gen]\n",
    "        row = gen_df[gen_df[\"cand_id\"] == cand_id].iloc[0]\n",
    "        cand_coords = [row[outcome] for outcome in outcomes]\n",
    "        cand_dict = dict(zip(outcomes.keys(), cand_coords))\n",
    "        cand_dict[\"cand_id\"] = cand_id\n",
    "        coords_dicts.append(cand_dict)\n",
    "\n",
    "    baseline_dict = {outcome: metric for outcome, metric in baseline_metrics.items()}\n",
    "    baseline_dict[\"cand_id\"] = \"Baseline\"\n",
    "    coords_dicts.append(baseline_dict)\n",
    "\n",
    "    coords_df = pd.DataFrame(coords_dicts)\n",
    "    normalized_df = coords_df[outcomes.keys()]\n",
    "    normalized_df = (normalized_df - normalized_df.mean()) / (normalized_df.std() + 1e-10)\n",
    "    normalized_df[\"cand_id\"] = coords_df[\"cand_id\"]\n",
    "    \n",
    "    colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "    # Color baseline black\n",
    "    colors[len(coords_df)-1] = \"black\" \n",
    "    pd.plotting.parallel_coordinates(normalized_df, \"cand_id\", color=colors)\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel(\"Normalized Value\")\n",
    "    plt.title(\"Parallel Coordinates of Sampled Candidates\")\n",
    "\n",
    "plot_parallel_coordinates(sample_points, results_df)\n",
    "print(final_pareto[final_pareto[\"cand_id\"].isin(sample_points)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_df(dfs: list[pd.DataFrame]):\n",
    "    avg_df = dfs[0].copy()\n",
    "    for df in dfs[1:]:\n",
    "        avg_df += df\n",
    "    avg_df /= len(dfs)\n",
    "    return avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_outcome_over_time(outcome: str, cand_ids: list[str], paris=False):\n",
    "    for cand_id in cand_ids:\n",
    "        _, cand_outcomes, _ = experimenter.get_candidate_results(cand_id)\n",
    "        avg_df = get_average_df(cand_outcomes)\n",
    "        plt.plot(range(1990, 2101), avg_df[outcome], label=f\"{cand_id}\")\n",
    "    plt.plot(range(1990, 2101), baseline_df[outcome], color=\"black\", label=\"Baseline\")\n",
    "    plt.axvline(x=2024, color=\"red\", linestyle=\"--\", label=\"Policy Start Year\")\n",
    "\n",
    "    if outcome == \"CO2 Equivalent Net Emissions\":\n",
    "        plt.axhline(y=0, color=\"gray\", linestyle=\"--\")\n",
    "        if paris:\n",
    "            plt.axhline(y=54.4789*0.55, color=\"orange\", linestyle=\"--\", label=\"Paris Agreement 45% Reduction\")\n",
    "            plt.axvline(x=2035, color=\"orange\", linestyle=\"--\")\n",
    "            plt.axvline(x=2050, color=\"gray\", linestyle=\"--\", label=\"Paris Agreement Net Zero\")\n",
    "\n",
    "    elif outcome == \"Temperature change from 1850\":\n",
    "        plt.axhline(y=2, color=\"gray\", linestyle=\"--\", label=\"Paris Agreement 2C\")\n",
    "        plt.axhline(y=1.5, color=\"gray\", linestyle=\"--\", label=\"Paris Agreement 1.5C\")\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    if len(cand_outcomes) > 1:\n",
    "        plt.title(f\"Average {outcome} over time over {len(cand_outcomes)} contexts\")\n",
    "    else:\n",
    "        plt.title(f\"{outcome} over time\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(outcome)\n",
    "    plt.show()\n",
    "\n",
    "paris = \"Emissions Above Paris Agreement\" in outcomes\n",
    "enroads_outcomes = [\"Temperature change from 1850\", \"Adjusted cost of energy per GJ\", \"Total Primary Energy Demand\"]\n",
    "for outcome in enroads_outcomes:\n",
    "    plot_outcome_over_time(outcome, sample_points, paris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_energy_usage(cand_ids):\n",
    "    fig, axes = plt.subplots(1, len(cand_ids), sharey=True, figsize=(7.5 * len(cand_ids), 5))\n",
    "    if len(cand_ids) == 1:\n",
    "        axes = [axes]\n",
    "    axes[0].set_ylabel(\"Energy (Exajoules / year)\")\n",
    "    for cand_id, ax in zip(cand_ids, axes):\n",
    "        cand_outcomes = None\n",
    "        if cand_id == \"baseline\":\n",
    "            cand_outcomes = baseline_df\n",
    "        else:\n",
    "            _, cand_outcomes, _ = experimenter.get_candidate_results(cand_id)\n",
    "            cand_outcomes = get_average_df(cand_outcomes)\n",
    "        colors = [\"brown\", \"red\", \"blue\", \"green\", \"pink\", \"lightblue\", \"orange\"]\n",
    "        energies = [\"coal\", \"oil\", \"gas\", \"renew and hydro\", \"bio\", \"nuclear\", \"new tech\"]\n",
    "        demands = [\n",
    "            \"Primary Energy Demand of coal\",\n",
    "            \"Primary Energy Demand of oil\",\n",
    "            \"Primary Energy Demand of gas\",\n",
    "            \"Primary Energy Demand of renew and hydro\",\n",
    "            \"Primary Energy Demand of bio\",\n",
    "            \"Primary energy demand of nuclear\",  # NOTE: There is weird capitalization here so we have to match it\n",
    "            \"Primary energy demand of new tech\",\n",
    "        ]\n",
    "\n",
    "        energy_df = cand_outcomes[demands]\n",
    "        for i, demand in enumerate(demands):\n",
    "            base = 0\n",
    "            if i != 0:\n",
    "                for j in range(i):\n",
    "                    base += energy_df[demands[j]]\n",
    "            if energy_df[demand].sum() == 0:\n",
    "                continue\n",
    "            ax.fill_between(range(1990, 2101), base, base + energy_df[demand], label=energies[i], color=colors[i], alpha=0.8)\n",
    "        if cand_id != \"baseline\" and len(outcomes) > 1:\n",
    "            ax.set_title(f\"Average Energy Usage for Candidate {cand_id}\")\n",
    "        else:\n",
    "            ax.set_title(f\"Energy Usage for {cand_id}\")\n",
    "        ax.set_xlabel(\"Year\")\n",
    "        ax.axvline(x=2024, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    plt.suptitle(\"Global Sources of Primary Energy\")\n",
    "    # Reverse the legend order\n",
    "    plt.legend(reversed(ax.get_legend_handles_labels()[0]), reversed(ax.get_legend_handles_labels()[1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_energy_difference(cand_id):\n",
    "    colors = [\"brown\", \"red\", \"blue\", \"green\", \"pink\", \"lightblue\", \"orange\"]\n",
    "    energies = [\"coal\", \"oil\", \"gas\", \"renew and hydro\", \"bio\", \"nuclear\", \"new tech\"]\n",
    "    demands = [\n",
    "        \"Primary Energy Demand of coal\",\n",
    "        \"Primary Energy Demand of oil\",\n",
    "        \"Primary Energy Demand of gas\",\n",
    "        \"Primary Energy Demand of renew and hydro\",\n",
    "        \"Primary Energy Demand of bio\",\n",
    "        \"Primary energy demand of nuclear\",  # NOTE: There is weird capitalization here so we have to match it\n",
    "        \"Primary energy demand of new tech\",\n",
    "    ]\n",
    "\n",
    "    _, cand_outcomes, _ = experimenter.get_candidate_results(cand_id)\n",
    "    avg_outcomes = get_average_df(cand_outcomes)\n",
    "    energy_df = avg_outcomes[demands]\n",
    "\n",
    "    energy_baseline = baseline_df[demands]\n",
    "\n",
    "    diff_df = energy_df - energy_baseline\n",
    "    plt.grid(axis=\"y\")\n",
    "    plt.bar(energies, diff_df.iloc[-1], color=colors)\n",
    "    plt.ylabel(\"Difference in Energy (Exajoules / year)\")\n",
    "    plt.xlabel(\"Energy Source\")\n",
    "    if len(cand_outcomes) > 1:\n",
    "        plt.title(f\"Average Difference in Energy from Baseline for {cand_id} in 2100 over {len(cand_outcomes)} contexts\")\n",
    "    else:\n",
    "        plt.title(f\"Difference in Energy from Baseline for {cand_id} in 2100\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = best_cand_ids\n",
    "plot_energy_usage(examples +  [\"baseline\"])\n",
    "plot_energy_difference(examples[0])\n",
    "plot_energy_difference(examples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to open the browser for each example\n",
    "# for example in examples:\n",
    "#     open_browser(results_dir, example, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enroads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
